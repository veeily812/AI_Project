
# ğŸ§  C3QG: Context-Controlled, Explainable, and Efficient Question Generation

This repository implements **C3QG**, a transformer-based question generation system built on top of FLAN-T5 with explainable and controllable output. It is designed for applications in **education**, **assessment**, and **AI transparency**.

Developed by [Phung Thao Vi](mailto:phungvi08123@gmail.com), [Satyam Mishra](mailto:satyam.entrprnr@gmail.com), [Vishwanath Bijalwan](mailto:vishwanath.bijalwan@gmail.com), and [Duc Tan Tran](mailto:tan.tranduc@phenikaa-uni.edu.vn).

---

## ğŸš€ Features

- âœ… **Instruction-tuned FLAN-T5** for natural and context-aware question generation
- âœ… **Context-controlled prompting** (works with single/multi-paragraph inputs)
- âœ… **Difficulty adjustment & beam sampling**
- âœ… **Token-level explainability** via **SHAP**
- âœ… **Multi-metric evaluation**: ROUGE, METEOR, BERTScore, CrossEntropy
- âœ… **Expert validation** and educational alignment (e.g., Bloom's Taxonomy)

---

## ğŸ“‚ Repository Structure

```
.
â”œâ”€â”€ Final_C3QG.ipynb               # Main notebook (full implementation and results)
â”œâ”€â”€ Final_Complete_of_Question_Gen.ipynb  # Optional cleaner version of QG pipeline
â”œâ”€â”€ README.md                      # You're here!
```

---

## ğŸ› ï¸ Installation

To run the notebook in Google Colab:

1. Open `Final_C3QG.ipynb` in Colab
2. Ensure you are using a GPU Runtime (`Runtime > Change runtime type > GPU`)
3. Run all cells

If running locally:

```bash
pip install transformers datasets shap evaluate nltk
```

---

## ğŸ“š Dataset

The system is trained and evaluated using:

- **SQuAD v2.0** (via HuggingFace Datasets)
- Augmented with: Wikipedia passages + Back-translation + Synonym replacement

---

## ğŸ“ˆ Evaluation Metrics

| Metric      | Purpose                        |
|-------------|--------------------------------|
| ROUGE       | Lexical overlap                |
| METEOR      | Paraphrastic fluency           |
| BERTScore   | Semantic similarity (F1)       |
| CrossEntropy| Training signal                |
| SHAP        | Token-level model attribution  |

---

## ğŸ’¡ Sample Usage

```python
context = "Renewable energy is becoming a critical part of global sustainability efforts."
generate_question(context, num_questions=3)
```

Returns:
- "What role does renewable energy play in sustainability?"
- "Why are countries investing in renewable energy?"
- "How does renewable energy help fight climate change?"

---

## ğŸ“Š Results

- +4.2% improvement in BERTScore F1 over T5/BART baselines
- +3.8% better METEOR fluency
- SHAP visualizations reveal interpretable token contributions
- Adaptive difficulty shows alignment with educational needs

---

## ğŸ“Œ Limitations

- Current version is trained on general-purpose text, not domain-specific
- Performance in zero-resource or cross-lingual settings is untested
- SHAP visualizations are slower on longer contexts

---

## ğŸ“„ Citation

If you use this work, please cite:

> Phung Thao Vi, Satyam Mishra, Vishwanath Bijalwan, Duc Tan Tran.  
> *C3QG: Context-Controlled, Explainable, and Efficient Question Generation with Transformers*. (2025)

---

## ğŸ¤ Acknowledgements

Special thanks to Vision Mentors Vietnam and SR University for infrastructure support.

---

## ğŸ“¬ Contact

For collaborations or questions, feel free to reach out via email:
- [phungvi08123@gmail.com](mailto:phungvi08123@gmail.com)
- [satyam.entrprnr@gmail.com](mailto:satyam.entrprnr@gmail.com)
